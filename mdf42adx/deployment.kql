//-------------------------------
// Setting up the database
//-------------------------------


// Signals Metadata Table
// Create the signals metadata table and change the encoding to accept very large files
// This change will reduce index, but it is ok as the signals need to be expanded as part of an ingestion policy.

.create table signals_metadata (name: string, source_uuid: guid, preparation_startDate: datetime, signals: dynamic, signals_comment: dynamic, signals_decoding: dynamic, comments: string) 

// Alter the policy to allow entries of any size

.alter column signals_metadata.signals policy encoding type="BigObject32"

.alter column signals_metadata.signals_comment policy encoding type="BigObject32"

.alter column signals_metadata.signals_decoding policy encoding type="BigObject32"

.alter column signals_metadata.comments policy encoding type="BigObject32"

// Create mapping command
.create table ['signals_metadata'] ingestion json mapping 'signals_metadata_mapping' '[{"column":"name", "Properties":{"Path":"$[\'name\']"}},{"column":"source_uuid", "Properties":{"Path":"$[\'source_uuid\']"}},{"column":"preparation_startDate", "Properties":{"Path":"$[\'preparation_startDate\']"}},{"column":"signals", "Properties":{"Path":"$[\'signals\']"}},{"column":"signals_comment", "Properties":{"Path":"$[\'signals_comment\']"}},{"column":"signals_decoding", "Properties":{"Path":"$[\'signals_decoding\']"}},{"column":"comments", "Properties":{"Path":"$[\'comments\']"}}]'

// Signals Table

// The table several fields to store values in a safe way.
.create table ['signals']  (['source_uuid']:string, ['group_index']:int, ['channel_index']:int, ['name']:string, ['unit']:string, ['timestamp']:real, ['timestamp_diff']:real, ['value']:real, ['value_int']:int, ['value_uint64']:decimal, ['value_string']:string, ['valueRaw']:decimal)

// Create mapping command
.create table ['signals'] ingestion parquet mapping 'signals_mapping' '[{"column":"source_uuid", "Properties":{"Path":"$[\'source_uuid\']"}},{"column":"group_index", "Properties":{"Path":"$[\'group_index\']"}},{"column":"channel_index", "Properties":{"Path":"$[\'channel_index\']"}},{"column":"name", "Properties":{"Path":"$[\'name\']"}},{"column":"unit", "Properties":{"Path":"$[\'unit\']"}},{"column":"timestamp", "Properties":{"Path":"$[\'timestamp\']"}},{"column":"timestamp_diff", "Properties":{"Path":"$[\'timestamp_diff\']"}},{"column":"value", "Properties":{"Path":"$[\'value\']"}},{"column":"value_int", "Properties":{"Path":"$[\'value_int\']"}},{"column":"value_uint64", "Properties":{"Path":"$[\'value_uint64\']"}},{"column":"value_string", "Properties":{"Path":"$[\'value_string\']"}},{"column":"valueRaw", "Properties":{"Path":"$[\'valueRaw\']"}}]'

//-------------------------------
// Create functions
//-------------------------------

.create-or-alter function with (folder = "Stats") TimeStatistics() {
// Calculate the duration of all recordings
signals
 | summarize Start=min(timestamp), End=max(timestamp)  by source_uuid
 | extend duration = (End - Start) * 1s
}

.create-or-alter function with (folder = "Stats") RecordingStatistics_Averages(T:(*)) {
// Finds the average value and does a pivot on the result
    signals
    | where name in (T)
    | evaluate pivot(name, avg(value), source_uuid)
}

.create-or-alter function with (folder = "Stats") RecordingStatistics_Max(T:(*)) {
// Calculate the max absolute value and pivot
    signals
    | where name in (T)
    | evaluate pivot(name, max(abs(value)), source_uuid)
}

.create-or-alter function with (folder = "Stats") TimeAbove(name:string,valueLimit:real) {
// calculate how long a signal is above a limit in all recordings
    signals
    | sort by source_uuid, timestamp asc
    | extend timeDifference = timestamp - prev(timestamp)
    | where value > valueLimit
    | summarize timeOver = sum(timeDifference)*1s by source_uuid
}
